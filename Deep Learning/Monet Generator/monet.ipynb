{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Monet-Style Images Using GANs\n",
    "\n",
    "## Description of the Problem\n",
    "\n",
    "Generative Adversarial Networks (GANs) are a class of neural networks used for generating new data that mimics a given dataset. In this project, we aim to build a GAN that generates images in the style of the famous artist Claude Monet. The goal is to generate between 7,000 to 10,000 Monet-style images.\n",
    "\n",
    "The GAN consists of two neural networks:\n",
    "\t•\tGenerator: Creates new images that resemble the Monet-style paintings.\n",
    "\t•\tDiscriminator: Distinguishes between real Monet paintings and images generated by the generator.\n",
    "\n",
    "These two networks are trained simultaneously in a game-theoretic framework where the generator tries to fool the discriminator, and the discriminator aims to correctly classify real and generated images.\n",
    "\n",
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Set the path to the dataset\n",
    "monet_path = 'path_to/monet_jpg/'\n",
    "photo_path = 'path_to/photo_jpg/'\n",
    "\n",
    "# Get the list of image file paths\n",
    "monet_images = glob(os.path.join(monet_path, '*.jpg'))\n",
    "photo_images = glob(os.path.join(photo_path, '*.jpg'))\n",
    "\n",
    "print(f'Total Monet images: {len(monet_images)}')\n",
    "print(f'Total Photo images: {len(photo_images)}')\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_image(image_path, img_size=(256, 256)):\n",
    "    img = load_img(image_path, target_size=img_size)\n",
    "    img = img_to_array(img)\n",
    "    img = (img - 127.5) / 127.5  # Normalize to [-1, 1]\n",
    "    return img\n",
    "\n",
    "# Load images into numpy arrays\n",
    "monet_data = np.array([load_and_preprocess_image(img) for img in monet_images])\n",
    "photo_data = np.array([load_and_preprocess_image(img) for img in photo_images])\n",
    "\n",
    "print(f'Monet data shape: {monet_data.shape}')\n",
    "print(f'Photo data shape: {photo_data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let’s visualize some samples from both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to display images\n",
    "def display_samples(data, title, n=5):\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.suptitle(title, fontsize=20)\n",
    "    for i in range(n):\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow((data[i] * 0.5 + 0.5))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "display_samples(monet_data, 'Monet Paintings')\n",
    "display_samples(photo_data, 'Photos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "\t•\tThe Monet paintings have distinctive brush strokes and color palettes.\n",
    "\t•\tThe photos are realistic images that we aim to translate into Monet’s style.\n",
    "\n",
    "### Building the GAN Model\n",
    "\n",
    "We will use a CycleGAN architecture, which is effective for image-to-image translation tasks.\n",
    "\n",
    "## Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    inputs = Input(shape=(256, 256, 3))\n",
    "\n",
    "    # Downsampling layers\n",
    "    x = Conv2D(64, kernel_size=4, strides=2, padding='same')(inputs)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    # Add more layers as needed...\n",
    "\n",
    "    # Upsampling layers\n",
    "    x = Conv2DTranspose(64, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    # Add more layers as needed...\n",
    "\n",
    "    outputs = Conv2D(3, kernel_size=7, padding='same', activation='tanh')(x)\n",
    "    model = Model(inputs, outputs, name='Generator')\n",
    "    return model\n",
    "\n",
    "generator = build_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    inputs = Input(shape=(256, 256, 3))\n",
    "\n",
    "    x = Conv2D(64, kernel_size=4, strides=2, padding='same')(inputs)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    # Add more layers as needed...\n",
    "\n",
    "    outputs = Conv2D(1, kernel_size=4, padding='same')(x)\n",
    "    model = Model(inputs, outputs, name='Discriminator')\n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Compiling the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "# Compile Discriminator\n",
    "discriminator.compile(loss='mse', optimizer=opt, loss_weights=[0.5])\n",
    "\n",
    "# Build and compile the combined model\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=(256, 256, 3))\n",
    "    generated_image = generator(gan_input)\n",
    "    gan_output = discriminator(generated_image)\n",
    "    gan = Model(gan_input, gan_output)\n",
    "    gan.compile(loss='mse', optimizer=opt)\n",
    "    return gan\n",
    "\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def train_gan(generator, discriminator, gan, epochs, batch_size):\n",
    "    real = np.ones((batch_size, 16, 16, 1))\n",
    "    fake = np.zeros((batch_size, 16, 16, 1))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch_i in range(len(photo_data) // batch_size):\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            idx = np.random.randint(0, photo_data.shape[0], batch_size)\n",
    "            real_imgs = monet_data[idx]\n",
    "\n",
    "            idx = np.random.randint(0, photo_data.shape[0], batch_size)\n",
    "            imgs = photo_data[idx]\n",
    "            fake_imgs = generator.predict(imgs)\n",
    "\n",
    "            d_loss_real = discriminator.train_on_batch(real_imgs, real)\n",
    "            d_loss_fake = discriminator.train_on_batch(fake_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "\n",
    "            g_loss = gan.train_on_batch(imgs, real)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} [D loss: {d_loss}] [G loss: {g_loss}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 1\n",
    "train_gan(generator, discriminator, gan, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Monet-Style Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def generate_images(generator, test_input):\n",
    "    prediction = generator.predict(test_input)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    for i in range(len(prediction)):\n",
    "        plt.subplot(1, len(prediction), i+1)\n",
    "        plt.imshow((prediction[i] * 0.5 + 0.5))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Select a few photos to translate\n",
    "test_photos = photo_data[:5]\n",
    "generate_images(generator, test_photos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Generated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "output_path = 'generated_images/'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "for i in range(len(photo_data)):\n",
    "    img = np.expand_dims(photo_data[i], axis=0)\n",
    "    gen_img = generator.predict(img)\n",
    "    gen_img = (gen_img[0] * 127.5 + 127.5).astype(np.uint8)\n",
    "    cv2.imwrite(os.path.join(output_path, f'monet_{i}.jpg'), cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "print(f\"Generated images saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and Conclusion\n",
    "\n",
    "In this project, we successfully built and trained a Generative Adversarial Network to generate images in the style of Monet. The generator learned to translate photos into Monet-style paintings, capturing the characteristic brush strokes and color palettes.\n",
    "\n",
    "### Challenges:\n",
    "\t•\tTraining Stability: GANs can be difficult to train due to the delicate balance between the generator and discriminator.\n",
    "\t•\tData Size: The quality of generated images can improve with more training data and longer training times.\n",
    "\n",
    "## Future Work:\n",
    "\t•\tModel Refinement: Experiment with different architectures and hyperparameters to improve the quality of the generated images.\n",
    "\t•\tEvaluation Metrics: Implement metrics like the Fréchet Inception Distance (FID) to quantitatively assess the quality of generated images.\n",
    "\n",
    "## References\n",
    "\n",
    "\t•\tGoodfellow, I. et al. (2014). Generative Adversarial Nets.\n",
    "\t•\tZhu, J. et al. (2017). Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
